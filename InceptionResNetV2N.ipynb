{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resize dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FakRWDPtXfXs",
        "colab_type": "text"
      },
      "source": [
        "The DICOM format is so cool, but I prefer normal images :)\n",
        "\n",
        "With 156GB (compressed) it is very difficult to work with the resources of the vast majority of the mortals.\n",
        "This notebook shows you how to scale down all the images and create a new dataset easier to deal with.\n",
        "Even with the best computing resources, I don't think it's necessary to use the original size to get good accuracy.\n",
        "\n",
        "If you feel that you need bigger images or you want to store the images in another format you only need to change a couple of lines in the next section (Constants).\n",
        "\n",
        "Some code taken from:\n",
        "* https://www.kaggle.com/omission/eda-view-dicom-images-with-correct-windowing\n",
        "* https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection/discussion/109649#latest-631701\n",
        "\n",
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnKnCkskkzKp",
        "colab_type": "code",
        "outputId": "33fc1c9d-de7f-408b-a1f0-e01dd0da69c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9VhPK8HoHt9",
        "colab_type": "text"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RQs59bLoL9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Uninstall and reinstall kaggle because I'm getting and error: the kaggle script\n",
        "# is running on Python 2 instead of Python 3 and fails when downloading kernel\n",
        "# outputs.\n",
        "# It's also needed for download data for this competition.\n",
        "!pip uninstall -y kaggle\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXxbGtzXB7BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Install this library for reading the *.dcm images of this competition.\n",
        "!pip install pydicom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgE9gVMQ4HP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Mount fuse-zip to mount zip files so we can access the files without unzip it.\n",
        "# This is needed because of the lack of space in Google Colab disk.\n",
        "!apt-get install -y fuse-zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inFQEaaMoKe2",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPNIQTvEmiXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "import joblib\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import PIL\n",
        "\n",
        "import pydicom\n",
        "\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAIvD7YYm7VB",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSQ1lTX4m8hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set environment variables for using the Kaggle API.\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"mobassir\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"878211beeff667d5b3240ed4c3daa6f6\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQmKznCJn6lU",
        "colab_type": "text"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl-PZYtsnCOA",
        "colab_type": "code",
        "outputId": "5a0099df-1ca9-4189-d1b3-b40c2cd6e4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# 30-45min in Google Colab.\n",
        "raw_data_dir = \"input/raw\"\n",
        "!kaggle competitions download -c rsna-intracranial-hemorrhage-detection -p {raw_data_dir}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading rsna-intracranial-hemorrhage-detection.zip to input/raw\n",
            "100% 180G/180G [17:00<00:00, 215MB/s]\n",
            "100% 180G/180G [17:00<00:00, 189MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bQaxTBsUFeF",
        "colab_type": "text"
      },
      "source": [
        "# Mount ZIP with fuse-zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrHBOVyYUJZa",
        "colab_type": "code",
        "outputId": "0236351d-ebb4-488e-aec7-0867b1751d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "# Around 10 min in Google Colab.\n",
        "\n",
        "input_dir = \"/tmp/kaggle-data\"\n",
        "!mkdir {input_dir}\n",
        "!fuse-zip input/raw/rsna-intracranial-hemorrhage-detection.zip {input_dir}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.29 s, sys: 147 ms, total: 1.43 s\n",
            "Wall time: 6min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE06xXqBWbws",
        "colab_type": "code",
        "outputId": "1a510578-dc96-4a1e-b9cf-9f823acd417c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Check that everything is working.\n",
        "!ls {input_dir}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rsna-intracranial-hemorrhage-detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqo9cUAiU6Eo",
        "colab_type": "text"
      },
      "source": [
        "# Get images path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGbtOYggcvbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dir = \"/tmp/kaggle-data/\" + 'rsna-intracranial-hemorrhage-detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yc5bNeOjpVa",
        "colab_type": "code",
        "outputId": "f529ffb7-7501-47b2-8aa7-ba6b4620b872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(input_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/kaggle-data/rsna-intracranial-hemorrhage-detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FsLeV_iYjdM",
        "colab_type": "code",
        "outputId": "2842bd5d-dc2c-46b7-96e3-739b2c10e5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dir = \"stage_2_train/\"\n",
        "train_paths = glob.glob(f\"{input_dir}/{train_dir}/*.dcm\")\n",
        "test_dir = \"stage_2_test/\"\n",
        "test_paths = glob.glob(f\"{input_dir}/{test_dir}/*.dcm\")\n",
        "len(train_paths), len(test_paths)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(752803, 121232)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Vmp18B7YuO",
        "colab_type": "code",
        "outputId": "6459acd3-5320-4831-8d1e-11295e41941d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import os\n",
        "import collections\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import multiprocessing\n",
        "\n",
        "from math import ceil, floor\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import Sequence\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "# Install Modules from internet\n",
        "!pip install efficientnet\n",
        "!pip install iterative-stratification\n",
        "\n",
        "# Import Custom Modules\n",
        "import efficientnet.keras as efn \n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.8.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (4.3.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.3.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->efficientnet) (0.46)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (41.4.0)\n",
            "Installing collected packages: efficientnet\n",
            "Successfully installed efficientnet-1.0.0\n",
            "Collecting iterative-stratification\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/79/9ba64c8c07b07b8b45d80725b2ebd7b7884701c1da34f70d4749f7b45f9a/iterative_stratification-0.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.17.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (0.14.0)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MciWRND6Iv5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed\n",
        "SEED = 12345\n",
        "np.random.seed(SEED)\n",
        "#tf.set_random_seed(SEED)\n",
        "\n",
        "# Constants\n",
        "TEST_SIZE = 0.1\n",
        "HEIGHT = 299\n",
        "WIDTH = 299\n",
        "CHANNELS = 3\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 16\n",
        "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
        "\n",
        "# Folders\n",
        "#DATA_DIR = '/kaggle/input/rsna-intracranial-hemorrhage-detection/'\n",
        "TEST_IMAGES_DIR = test_dir\n",
        "TRAIN_IMAGES_DIR = train_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMnLIunV7Yox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_dcm(dcm):\n",
        "    x = dcm.pixel_array + 1000\n",
        "    px_mode = 4096\n",
        "    x[x>=px_mode] = x[x>=px_mode] - px_mode\n",
        "    dcm.PixelData = x.tobytes()\n",
        "    dcm.RescaleIntercept = -1000\n",
        "\n",
        "def window_image(dcm, window_center, window_width):    \n",
        "    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n",
        "        correct_dcm(dcm)\n",
        "    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n",
        "    \n",
        "    # Resize\n",
        "    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n",
        "   \n",
        "    img_min = window_center - window_width // 2\n",
        "    img_max = window_center + window_width // 2\n",
        "    img = np.clip(img, img_min, img_max)\n",
        "    return img\n",
        "\n",
        "def bsb_window(dcm):\n",
        "    brain_img = window_image(dcm, 40, 80)\n",
        "    subdural_img = window_image(dcm, 80, 200)\n",
        "    soft_img = window_image(dcm, 40, 380)\n",
        "    \n",
        "    brain_img = (brain_img - 0) / 80\n",
        "    subdural_img = (subdural_img - (-20)) / 200\n",
        "    soft_img = (soft_img - (-150)) / 380\n",
        "    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n",
        "    return bsb_img\n",
        "\n",
        "def _read(path, SHAPE):\n",
        "    dcm = pydicom.dcmread(path)\n",
        "    try:\n",
        "        img = bsb_window(dcm)\n",
        "    except:\n",
        "        img = np.zeros(SHAPE)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55q8GQZDGawc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "363167c9-05dc-441d-8086-53d51908746c"
      },
      "source": [
        "print(os.listdir('./input/raw/'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rsna-intracranial-hemorrhage-detection.zip']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1WpH-Z27YlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsyuE1lZ7Ygs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Augmentation\n",
        "sometimes = lambda aug: iaa.Sometimes(0.25, aug)\n",
        "augmentation = iaa.Sequential([ iaa.Fliplr(0.25),\n",
        "                                iaa.Flipud(0.10),\n",
        "                                sometimes(iaa.Crop(px=(0, 25), keep_size = True, sample_independently = False))   \n",
        "                            ], random_order = True)       \n",
        "        \n",
        "# Generators\n",
        "class TrainDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, dataset, labels, batch_size = 16, img_size = SHAPE, img_dir = TRAIN_IMAGES_DIR, augment = False, *args, **kwargs):\n",
        "        self.dataset = dataset\n",
        "        self.ids = dataset.index\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.img_dir = input_dir+\"/\"+img_dir\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(ceil(len(self.ids) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X, Y = self.__data_generation(indices)\n",
        "        return X, Y\n",
        "\n",
        "    def augmentor(self, image):\n",
        "        augment_img = augmentation        \n",
        "        image_aug = augment_img.augment_image(image)\n",
        "        return image_aug\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.ids))\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "    def __data_generation(self, indices):\n",
        "        X = np.empty((self.batch_size, *self.img_size))\n",
        "        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n",
        "        \n",
        "        for i, index in enumerate(indices):\n",
        "            ID = self.ids[index]\n",
        "            image = _read(self.img_dir+ID+\".dcm\", self.img_size)########\n",
        "            if self.augment:\n",
        "                X[i,] = self.augmentor(image)\n",
        "            else:\n",
        "                X[i,] = image\n",
        "            Y[i,] = self.labels.iloc[index].values        \n",
        "        return X, Y\n",
        "    \n",
        "class TestDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, dataset, labels, batch_size = 16, img_size = SHAPE, img_dir = TEST_IMAGES_DIR, *args, **kwargs):\n",
        "        self.dataset = dataset\n",
        "        self.ids = dataset.index\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.img_dir = input_dir+\"/\"+img_dir\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(ceil(len(self.ids) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X = self.__data_generation(indices)\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.ids))\n",
        "    \n",
        "    def __data_generation(self, indices):\n",
        "        X = np.empty((self.batch_size, *self.img_size))\n",
        "        \n",
        "        for i, index in enumerate(indices):\n",
        "            ID = self.ids[index]\n",
        "            image = _read(self.img_dir+ID+\".dcm\", self.img_size)########\n",
        "            X[i,] = image              \n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S76bWDBKNIfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "84eefc2b-3ba3-4fbf-8f2e-e45636689d71"
      },
      "source": [
        "a = pd.read_csv(input_dir + \"/stage_2_train.csv\")\n",
        "a.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_12cadc6af_epidural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_12cadc6af_intraparenchymal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_12cadc6af_intraventricular</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_12cadc6af_subarachnoid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_12cadc6af_subdural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              ID  Label\n",
              "0          ID_12cadc6af_epidural      0\n",
              "1  ID_12cadc6af_intraparenchymal      0\n",
              "2  ID_12cadc6af_intraventricular      0\n",
              "3      ID_12cadc6af_subarachnoid      0\n",
              "4          ID_12cadc6af_subdural      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ckrlFOQWD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bigdata_duplicates = a[a.duplicated()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVGQ2i1dQjYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f2bda677-a3ec-499f-f38f-b7f7b8a69ac6"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4516842, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN8xXshxQnxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "36f0916a-147b-4cc3-8690-1397ea0d60b9"
      },
      "source": [
        "df_bigdata_duplicates"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56346</th>\n",
              "      <td>ID_a64d5deed_epidural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56347</th>\n",
              "      <td>ID_a64d5deed_intraparenchymal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56348</th>\n",
              "      <td>ID_a64d5deed_intraventricular</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56349</th>\n",
              "      <td>ID_a64d5deed_subarachnoid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56350</th>\n",
              "      <td>ID_a64d5deed_subdural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56351</th>\n",
              "      <td>ID_a64d5deed_any</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171830</th>\n",
              "      <td>ID_854fba667_epidural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171831</th>\n",
              "      <td>ID_854fba667_intraparenchymal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171832</th>\n",
              "      <td>ID_854fba667_intraventricular</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171833</th>\n",
              "      <td>ID_854fba667_subarachnoid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171834</th>\n",
              "      <td>ID_854fba667_subdural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171835</th>\n",
              "      <td>ID_854fba667_any</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705312</th>\n",
              "      <td>ID_489ae4179_epidural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705313</th>\n",
              "      <td>ID_489ae4179_intraparenchymal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705314</th>\n",
              "      <td>ID_489ae4179_intraventricular</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705315</th>\n",
              "      <td>ID_489ae4179_subarachnoid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705316</th>\n",
              "      <td>ID_489ae4179_subdural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705317</th>\n",
              "      <td>ID_489ae4179_any</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842478</th>\n",
              "      <td>ID_921490062_epidural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842479</th>\n",
              "      <td>ID_921490062_intraparenchymal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842480</th>\n",
              "      <td>ID_921490062_intraventricular</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842481</th>\n",
              "      <td>ID_921490062_subarachnoid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842482</th>\n",
              "      <td>ID_921490062_subdural</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842483</th>\n",
              "      <td>ID_921490062_any</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    ID  Label\n",
              "56346            ID_a64d5deed_epidural      0\n",
              "56347    ID_a64d5deed_intraparenchymal      0\n",
              "56348    ID_a64d5deed_intraventricular      0\n",
              "56349        ID_a64d5deed_subarachnoid      0\n",
              "56350            ID_a64d5deed_subdural      0\n",
              "56351                 ID_a64d5deed_any      0\n",
              "1171830          ID_854fba667_epidural      0\n",
              "1171831  ID_854fba667_intraparenchymal      0\n",
              "1171832  ID_854fba667_intraventricular      0\n",
              "1171833      ID_854fba667_subarachnoid      0\n",
              "1171834          ID_854fba667_subdural      0\n",
              "1171835               ID_854fba667_any      0\n",
              "3705312          ID_489ae4179_epidural      0\n",
              "3705313  ID_489ae4179_intraparenchymal      0\n",
              "3705314  ID_489ae4179_intraventricular      0\n",
              "3705315      ID_489ae4179_subarachnoid      0\n",
              "3705316          ID_489ae4179_subdural      0\n",
              "3705317               ID_489ae4179_any      0\n",
              "3842478          ID_921490062_epidural      0\n",
              "3842479  ID_921490062_intraparenchymal      0\n",
              "3842480  ID_921490062_intraventricular      0\n",
              "3842481      ID_921490062_subarachnoid      0\n",
              "3842482          ID_921490062_subdural      0\n",
              "3842483               ID_921490062_any      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fddS33gm7Yed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_testset(filename = input_dir + \"/stage_2_sample_submission.csv\"):\n",
        "    df = pd.read_csv(filename)\n",
        "    df[\"Image\"] = df[\"ID\"].str.slice(stop=12)\n",
        "    df[\"Diagnosis\"] = df[\"ID\"].str.slice(start=13)\n",
        "    df = df.loc[:, [\"Label\", \"Diagnosis\", \"Image\"]]\n",
        "    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)\n",
        "    return df\n",
        "\n",
        "def read_trainset(filename = input_dir + \"/stage_2_train.csv\"):\n",
        "    df = pd.read_csv(filename)\n",
        "    df[\"Image\"] = df[\"ID\"].str.slice(stop=12)\n",
        "    df[\"Diagnosis\"] = df[\"ID\"].str.slice(start=13)\n",
        "    #duplicates_to_remove = [\n",
        "     #   1598538, 1598539, 1598540, 1598541, 1598542, 1598543,\n",
        "     #   312468,  312469,  312470,  312471,  312472,  312473,\n",
        "     #   2708700, 2708701, 2708702, 2708703, 2708704, 2708705,\n",
        "     #   3032994, 3032995, 3032996, 3032997, 3032998, 3032999\n",
        "  #  ]\n",
        "    #df = df.drop(index = duplicates_to_remove)\n",
        "\n",
        "    duplicates_to_remove = [\n",
        "        56346,56347,56348,56349,\n",
        "        56350,56351,1171830,1171831,\n",
        "        1171832,1171833,1171834,1171835,\n",
        "        3705312,3705313,3705314,3705315,\n",
        "        3705316,3705317,3842478,3842479,\n",
        "        3842480,3842481,3842482,3842483\n",
        "    ]\n",
        "    df = df.drop(index = duplicates_to_remove)\n",
        "\n",
        "    df = df.reset_index(drop = True)    \n",
        "    df = df.loc[:, [\"Label\", \"Diagnosis\", \"Image\"]]\n",
        "    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)\n",
        "    return df\n",
        "\n",
        "# Read Train and Test Datasets\n",
        "test_df = read_testset()\n",
        "train_df = read_trainset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t6J8SCR7YbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "131c5c08-4da2-4de4-b369-f3d518239ba2"
      },
      "source": [
        "# Oversampling\n",
        "epidural_df = train_df[train_df.Label['epidural'] == 1]\n",
        "epidural_df1 = train_df[train_df.Label['epidural'] == 1]\n",
        "train_oversample_df = pd.concat([train_df, epidural_df])\n",
        "train_oversample_df = pd.concat([train_oversample_df, epidural_df1])\n",
        "train_df = train_oversample_df\n",
        "\n",
        "# Summary\n",
        "print('Train Shape: {}'.format(train_df.shape))\n",
        "print('Test Shape: {}'.format(test_df.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Shape: (759093, 6)\n",
            "Test Shape: (121232, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Q0PHanxX7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epidural_df1 = train_df[train_df.Label['epidural'] == 1]\n",
        "\n",
        "intraparenchymal_df1 = train_df[train_df.Label['intraparenchymal'] == 1]\n",
        "\n",
        "subdural_df1 = train_df[train_df.Label['subdural'] == 1]\n",
        "\n",
        "intraventricular_df1 = train_df[train_df.Label['intraventricular'] == 1]\n",
        "\n",
        "subarachnoid_df1 = train_df[train_df.Label['subarachnoid'] == 1]\n",
        "\n",
        "any_df1 = train_df[train_df.Label['any'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crF_cyPD7YZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "def predictions(test_df, model):    \n",
        "    test_preds = model.predict_generator(TestDataGenerator(test_df, None, 5, SHAPE, TEST_IMAGES_DIR), verbose = 1)\n",
        "    return test_preds[:test_df.iloc[range(test_df.shape[0])].shape[0]]\n",
        "\n",
        "def ModelCheckpointFull(model_name):\n",
        "    return ModelCheckpoint(filepath + model_name, \n",
        "                            monitor = 'val_loss', \n",
        "                            verbose = 1, \n",
        "                            save_best_only = False, \n",
        "                            save_weights_only = True, \n",
        "                            mode = 'min', \n",
        "                            period = 1)\n",
        "\n",
        "# Create Model\n",
        "def create_model():\n",
        "    #K.clear_session()\n",
        "    \n",
        "    base_model =  InceptionResNetV2(weights = 'imagenet', include_top = False, pooling = 'avg', input_shape = SHAPE)\n",
        "    #base_model.load_weights(filepath+'model.h5')\n",
        "    x = base_model.output\n",
        "    x = Dropout(0.15)(x)\n",
        "    y_pred = Dense(6, activation = 'sigmoid')(x)\n",
        "\n",
        "    return Model(inputs = base_model.input, outputs = y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzGG1OYD7YV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Submission Placeholder\n",
        "submission_predictions = []\n",
        "\n",
        "# Multi Label Stratified Split stuff...\n",
        "msss = MultilabelStratifiedShuffleSplit(n_splits = 10, test_size = TEST_SIZE, random_state = SEED)\n",
        "X = train_df.index\n",
        "Y = train_df.Label.values\n",
        "\n",
        "# Get train and test index\n",
        "msss_splits = next(msss.split(X, Y))\n",
        "train_idx = msss_splits[0]\n",
        "valid_idx = msss_splits[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzXsFfa7YTa",
        "colab_type": "code",
        "outputId": "f4bd07e2-7b6b-42f0-b8fb-71938955a6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# Loop through Folds of Multi Label Stratified Split\n",
        "#for epoch, msss_splits in zip(range(0, 9), msss.split(X, Y)): \n",
        "#    # Get train and test index\n",
        "#    train_idx = msss_splits[0]\n",
        "#    valid_idx = msss_splits[1]\n",
        "LR = 0.00015\n",
        "for epoch in range(0, 3):\n",
        "    print('=========== EPOCH {}'.format(epoch))\n",
        "\n",
        "    # Shuffle Train data\n",
        "    np.random.shuffle(train_idx)\n",
        "    print(train_idx[:5])    \n",
        "    print(valid_idx[:5])\n",
        "\n",
        "    # Create Data Generators for Train and Valid\n",
        "    data_generator_train = TrainDataGenerator(train_df.iloc[train_idx], \n",
        "                                                train_df.iloc[train_idx], \n",
        "                                                TRAIN_BATCH_SIZE, \n",
        "                                                SHAPE,\n",
        "                                                augment = True)\n",
        "    data_generator_val = TrainDataGenerator(train_df.iloc[valid_idx], \n",
        "                                            train_df.iloc[valid_idx], \n",
        "                                            VALID_BATCH_SIZE, \n",
        "                                            SHAPE,\n",
        "                                            augment = False)\n",
        "\n",
        "    # Create Model\n",
        "    model = create_model()\n",
        "    \n",
        "    # Full Training Model\n",
        "    for base_layer in model.layers[:-1]:\n",
        "      base_layer.trainable = True\n",
        "      TRAIN_STEPS = int(len(data_generator_train) / 7)\n",
        "      TRAIN_STEPS = TRAIN_STEPS + 1000\n",
        "      model.load_weights(filepath + \"model2.h5\")\n",
        "      # Load Model Weights\n",
        "      '''if epoch != 0:\n",
        "        a = filepath + \"model2.h5\"\n",
        "        model.load_weights(a)'''\n",
        "        \n",
        "\n",
        "    model.compile(optimizer = Adam(LR), \n",
        "                  loss = 'binary_crossentropy',\n",
        "                  metrics = ['acc'])\n",
        "    \n",
        "    # Train Model\n",
        "    model.fit_generator(generator = data_generator_train,\n",
        "                        validation_data = data_generator_val,\n",
        "                        steps_per_epoch = TRAIN_STEPS,\n",
        "                        epochs = 1,\n",
        "                        callbacks = [ModelCheckpointFull('model2.h5')],\n",
        "                        verbose = 1)\n",
        "    \n",
        "    # Starting with the 6th epoch we create predictions for the test set on each epoch\n",
        "    if epoch >= 0:\n",
        "        preds = predictions(test_df, model)\n",
        "        submission_predictions.append(preds)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== EPOCH 0\n",
            "[185615 324124 178720 226433 401865]\n",
            "[ 0 17 30 31 37]\n",
            "Epoch 1/1\n",
            "4050/4050 [==============================] - 4125s 1s/step - loss: 0.0700 - acc: 0.9748 - val_loss: 0.0656 - val_acc: 0.9762\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/model2.h5\n",
            "24247/24247 [==============================] - 2149s 89ms/step\n",
            "=========== EPOCH 1\n",
            "[366490 685728 123319 215141 223538]\n",
            "[ 0 17 30 31 37]\n",
            "Epoch 1/1\n",
            "4050/4050 [==============================] - 4136s 1s/step - loss: 0.0683 - acc: 0.9754 - val_loss: 0.0654 - val_acc: 0.9765\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/model2.h5\n",
            "24247/24247 [==============================] - 2201s 91ms/step\n",
            "=========== EPOCH 2\n",
            "[126486  25129 432111 594160 394635]\n",
            "[ 0 17 30 31 37]\n",
            "Epoch 1/1\n",
            "4050/4050 [==============================] - 4176s 1s/step - loss: 0.0668 - acc: 0.9759 - val_loss: 0.0665 - val_acc: 0.9761\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/model2.h5\n",
            "24247/24247 [==============================] - 2273s 94ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjBH-1Ia7YQW",
        "colab_type": "code",
        "outputId": "c01452e8-e39b-4a85-ae7b-8839b9eea5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "test_df.iloc[:, :] = np.average(submission_predictions, axis = 0, weights = [2**i for i in range(len(submission_predictions))])\n",
        "test_df = test_df.stack().reset_index()\n",
        "test_df.insert(loc = 0, column = 'ID', value = test_df['Image'].astype(str) + \"_\" + test_df['Diagnosis'])\n",
        "test_df = test_df.drop([\"Image\", \"Diagnosis\"], axis=1)\n",
        "test_df.to_csv('submission.csv', index = False)\n",
        "print(test_df.head(12))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                               ID         Label\n",
            "0                ID_000000e27_any  3.961421e-02\n",
            "1           ID_000000e27_epidural  2.576411e-04\n",
            "2   ID_000000e27_intraparenchymal  2.741226e-03\n",
            "3   ID_000000e27_intraventricular  1.700606e-04\n",
            "4       ID_000000e27_subarachnoid  3.225914e-02\n",
            "5           ID_000000e27_subdural  1.083157e-02\n",
            "6                ID_000009146_any  5.437221e-05\n",
            "7           ID_000009146_epidural  1.370907e-06\n",
            "8   ID_000009146_intraparenchymal  1.515661e-06\n",
            "9   ID_000009146_intraventricular  4.981245e-07\n",
            "10      ID_000009146_subarachnoid  1.217212e-05\n",
            "11          ID_000009146_subdural  1.987389e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SnFX0pgaa_Qs",
        "colab": {}
      },
      "source": [
        "\n",
        "!cp submission.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1ZFIUkF7YMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}